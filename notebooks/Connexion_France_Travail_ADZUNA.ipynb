{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598d621d-ffac-4fe6-8e18-07c055e9d366",
   "metadata": {},
   "source": [
    "# Connexion_France_Travail_ADZUNA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e368b-be9e-4195-b2ab-5f3eebcdcc12",
   "metadata": {},
   "source": [
    "Ce script a pour objectif :\n",
    "- d'extraire les offres d'emploi mises √† disposition par :\n",
    "  <br> _ l'API de **France Travail**\n",
    "  <br>_ de l'API **ADZUNA**\n",
    "- les stocker dans :\n",
    "  <br> _ un fichier (**CSV**) en local\n",
    "  <br> _ un fichier (**Parquet**) en local\n",
    "  <br> _ dans une **BDD PostgreSQL** en local.\n",
    "\n",
    "**/!\\ Ajouts !** : \n",
    "- Ajout d'une boucle for pour lancer 2 fois le pipeline (pour 2 requ√™tes diff√©rentes).\n",
    "- Modification des r√©pertoires pour le suivi des candidatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129f84d-2d01-44eb-ba17-25d4cf673d3c",
   "metadata": {},
   "source": [
    "Comment ?\n",
    "1. Sur la base de crit√®res sp√©cifiques (mots cl√©s, localisation, etc...), \n",
    "    - lancement d'une requ√™te pour obtenir les offres d'emploi correspondantes via l'API France Travail\n",
    "    - lancement d'une requ√™te pour obtenir les offres d'emploi correspondantes via l'API Adzuna\n",
    "2. Une fois les offres trouv√©es, v√©rification et suppression des doublons.\n",
    "3. Une sauvegarde en local des offres sont stock√©es dans un fichier (**CSV**).\n",
    "4. Une sauvegarde en local des offres sont stock√©es dans un fichier (**Parquet**).\n",
    "5. Une sauvegarde dans une base de donn√©es **PostgreSQL** est √©galement effectu√©e en local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6874620-7676-4138-9b30-0ac53198d8f1",
   "metadata": {},
   "source": [
    "Les URL (FRANCE TRAVAIL) utiles sont :\n",
    "- https://francetravail.io/data/api/offres-emploi\n",
    "- https://francetravail.io/data/api/offres-emploi/documentation#/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736e6c8-5d60-47e3-8eb8-cbf900de62c1",
   "metadata": {},
   "source": [
    "Les URL (ADZUNA) utiles sont :\n",
    "- https://developer.adzuna.com/overview\n",
    "- https://developer.adzuna.com/docs/search\n",
    "- https://developer.adzuna.com/activedocs#!/adzuna/search\n",
    "- https://developer.adzuna.com/overview\n",
    "- https://www.adzuna.fr/details/5376850320?utm_medium=api&utm_source=6d1ef246"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b6efe-f320-4b0d-86ec-44109e1620b6",
   "metadata": {},
   "source": [
    "URL utile pour r√©cup√©rer les informations g√©ographiques:\n",
    "- https://www.data.gouv.fr/datasets/contours-communes-france-administrative-format-admin-express-avec-arrondissements/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77453b-9814-4567-97aa-7f680bfdfe9b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59e94172-c17e-4a12-9519-d1b26cd600df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, Table, MetaData, text\n",
    "from sqlalchemy.dialects.postgresql import insert as pg_insert\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import http.client\n",
    "import json\n",
    "import hashlib\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742dd34f-6c24-4f94-b985-40336f97d531",
   "metadata": {},
   "source": [
    "## Proc√©dure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d771d39-0166-45aa-abda-90d58d82f440",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17e18cf1-1961-4200-9bb9-497ce803db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################  VARIABLES  ##################\n",
    "# France Travail\n",
    "FT_CLIENT_ID = os.environ.get(\"FT_CLIENT_ID\")\n",
    "FT_CLIENT_SECRET = os.environ.get(\"FT_CLIENT_SECRET\")\n",
    "FT_SCOPE = os.environ.get(\"FT_SCOPE\")\n",
    "\n",
    "# Adzuna\n",
    "ADZUNA_CLIENT_ID = os.environ.get(\"ADZUNA_CLIENT_ID\")\n",
    "ADZUNA_CLIENT_SECRET = os.environ.get(\"ADZUNA_CLIENT_SECRET\")\n",
    "\n",
    "# Param Database PostgreSQL\n",
    "DB_NAME = os.environ.get(\"DB_NAME\", \"jobsdb\")\n",
    "DB_USER = os.environ.get(\"DB_USER\",\"jobsuser\")\n",
    "DB_PASS = os.environ.get(\"DB_PASS\", \"jobspass\")\n",
    "DB_HOST = os.environ.get(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.environ.get(\"DB_PORT\",\"5432\")\n",
    "\n",
    "# Nom table\n",
    "DB_TABLE_NAME = \"offres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f0bec-9475-4dd1-92d6-f6a21a487f7e",
   "metadata": {},
   "source": [
    "### Configuration Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa3f970c-1849-454a-8191-ebe47ac0008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "LOG_DIR = \"logs\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(LOG_DIR, f\"pipeline_{datetime.now().strftime('%Y-%m-%d')}.log\"),\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7dbbdb-2ef2-494a-ad27-31bb79f36ba1",
   "metadata": {},
   "source": [
    "### NLP ET embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f627bbe-919e-48bf-917d-0f50965505a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP & embeddings\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c6b29-9af0-4439-a594-b5527a2dee1d",
   "metadata": {},
   "source": [
    "### Texte de r√©f√©rence (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18f34d4e-8de1-45c8-a307-edcd2505f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offre de r√©f√©rence\n",
    "reference_text = \"\"\"\n",
    "-\tData Analyst\n",
    "-\tData Scientist\n",
    "-\tData Analyst en reconversion\n",
    "-\t10 ans d‚Äôexp√©rience industrie automobile & achats\n",
    "-\tExpert en dashboards et optimisation de performance\n",
    "\n",
    "-\tLocalisation :\n",
    "o\tIle-de-France\n",
    "o\tYvelines\n",
    "o\tPoissy\n",
    "o\t78\n",
    "\n",
    "-\tComp√©tences :\n",
    "o\tData Analysis & BI : Power BI (DAX, Power Query), Excel avanc√©, SQL.\n",
    "o\tData Visualization : Cr√©ation de tableaux de bord et KPIs pour la prise de d√©cision.\n",
    "o\tStatistiques & Pr√©visions : Analyses quantitatives, mod√®les pr√©dictifs, pr√©ventions des risques.\n",
    "o\tConception d‚Äôoutils d‚Äôaide √† la d√©cision et de tableaux de bord strat√©giques\n",
    "o\tM√©thodologies : Gestion de projets analytiques, reporting automatis√©.\n",
    "o\tExploitation de solutions de Data Science & Intelligence Artificielle : Machine Learning, mod√®les pr√©dictifs, classification, r√©gression, clustering\n",
    "o\tAnalyses et mod√©lisations statistiques avanc√©es : Python, outils BI, Dataiku\n",
    "o\tGestion et structuration de donn√©es massives : SQL Server, MySQL, Cloud Azure (Machine Learning Studio).\n",
    "o\tD√©veloppement et optimisation d‚Äôalgorithmes : pour la performance et l‚Äôautomatisation.\n",
    "o\tConception d‚Äôoutils d‚Äôaide √† la d√©cision et de tableaux de bord strat√©giques pour orienter les choix business.\n",
    "\n",
    "-\tInformatique :\n",
    "o\tLangages de programmation : Python, Java, SQL\n",
    "o\tLogiciel : Power BI, Excel, Dataiku, Jupyter Notebook\n",
    "o\tCloud : Azure, Google Cloud Platform\n",
    "\n",
    "-\tDipl√¥mes et Formations :\n",
    "o\tCertification Microsoft Analyste de Donn√©es Power BI (PL300)\n",
    "o\tBac+4 - Concepteur d√©veloppeur en IA et analyse Big Data\n",
    "o\tBac+5 ‚ÄìMaster 2 Electronique Electrotechnique et Automatique\n",
    "\n",
    "-\tAtouts :\n",
    "o\tAutonome et rigoureux dans la gestion de projets.\n",
    "o\tVulgarise des r√©sultats complexes pour des non-sp√©cialistes.\n",
    "o\tOrganise et priorise les t√¢ches orient√©es r√©sultats.\n",
    "o\tEn veille active sur l‚ÄôIA et les nouvelles technologies.\n",
    "o\tCurieux\n",
    "o\tAutonome et rigoureux\n",
    "o\tForce de proposition\n",
    "o\tA l'√©coute\n",
    "o\tEsprit d'√©quipe\n",
    "-\tLangues : Anglais courant\n",
    "-\tExp√©riences professionnelles : \n",
    "o\tAcheteur de composants : \n",
    "ÔÇß\tAnalyser et structurer des donn√©es fournisseurs pour l‚Äôoptimisation des co√ªts.\n",
    "ÔÇß\tD√©velopper des tableaux de bord (KPI, suivi de performance) automatis√©s.\n",
    "ÔÇß\tCommuniquer des insights aux √©quipes finance, qualit√© et production.\n",
    "ÔÇß\tR√©aliser des √©conomies sup√©rieures de 20 % aux objectifs fix√©s.\n",
    "ÔÇß\tAnalyser et structurer des donn√©es massives pour optimiser les co√ªts et la performance fournisseurs.\n",
    "ÔÇß\tCr√©er et automatiser de tableaux de bord (Power BI, Excel avanc√©) pour le suivi des KPIs.\n",
    "ÔÇß\tD√©velopper des mod√®les pr√©dictifs pour la pr√©vision des co√ªts et l‚Äôanalyse de tendances.\n",
    "ÔÇß\tG√©rer des projets interfonctionnels (production, finance, qualit√©), g√©n√©rant +20 % d‚Äô√©conomies au-del√† des objectifs.\n",
    "o\tResponsable de d√©veloppement de machines √©lectrique :\n",
    "ÔÇß\tAnalyser et valider des donn√©es issues des tests de performance produits.\n",
    "ÔÇß\tAutomatiser des traitements statistiques pour r√©duire les erreurs de reporting.\n",
    "ÔÇß\tMettre en place de mod√®les pr√©dictifs pour am√©liorer la fiabilit√© des composants.\n",
    "ÔÇß\tConcevoir des solutions analytiques pour optimiser la durabilit√© et la performance des composants.\n",
    "ÔÇß\tCollaborer en mode Agile avec √©quipes R&D et Data pour int√©grer l‚Äôanalyse dans l‚Äôam√©lioration continue.\n",
    "ÔÇß\tAnalyse statistique et validation de donn√©es issues de tests de performance.\n",
    "-\tCentres d‚Äôint√©r√™t :\n",
    "o\tTh√©√¢tre : Improvisation\n",
    "o\tMoto : Sorties en groupe\n",
    "\"\"\"\n",
    "reference_text_clean = \" \".join([token.lemma_ for token in nlp(reference_text.lower()) if not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc9df97e-5380-49d2-b091-d1e2e5886be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Offre de r√©f√©rence\n",
    "# reference_text = \"\"\"\n",
    "# Data Analyst avec expertise Python, SQL, Power BI et analyse de donn√©es industrielles.\n",
    "# \"\"\"\n",
    "# reference_text_clean = \" \".join([token.lemma_ for token in nlp(reference_text.lower()) if not token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631ac5b-b706-486a-bea2-e47ef6a4f9a4",
   "metadata": {},
   "source": [
    "### Param√®tres de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c47f4fc-a8ce-482c-ae6d-250061c5682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# PARAMETRES DE RECHERCHE\n",
    "# ---------------------------\n",
    "\n",
    "# Param√®tres de recherche\n",
    "# JOB_QUERY = \"data analyst\"\n",
    "COMMUNE = \"78300\"\n",
    "DISTANCE = 100000\n",
    "\n",
    "# Nombre d'annonces par page requise\n",
    "BLOC_PAGINATION = 50\n",
    "\n",
    "# Nombre de pages max\n",
    "MAX_PAGES = 20   # Limiter le nombre de pages r√©cup√©r√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c2baf-0c81-4879-9cbb-7d3cad0f33a0",
   "metadata": {},
   "source": [
    "### Param√®tres de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13daef8d-56fc-4538-994e-cecd5e78e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# PARAMETRES DE SAUVEGARDE\n",
    "# ---------------------------\n",
    "# R√©pertoires\n",
    "# Raw_data\n",
    "CSV_DIR_RAW = \"../data/raw_data/csv\"\n",
    "PARQUET_DIR_RAW = \"../data/raw_data/parquet\"\n",
    "\n",
    "# Processed_data\n",
    "CSV_DIR_PROC = \"../data/processed_data/csv\"\n",
    "PARQUET_DIR_PROC = \"../data/processed_data/parquet\"\n",
    "EXCEL_DIR_PROC = \"../data/processed_data/excel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b50db3-037e-4050-b095-393fd8ca5aa1",
   "metadata": {},
   "source": [
    "### Authentification France Travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af447536-bcf7-4def-8b46-a45c510ff850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# AUTH FRANCE TRAVAIL\n",
    "# ---------------------------\n",
    "def get_ft_token(retries=3, wait=5):\n",
    "    url = \"https://entreprise.pole-emploi.fr/connexion/oauth2/access_token?realm=/partenaire\"\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": FT_CLIENT_ID,\n",
    "        \"client_secret\": FT_CLIENT_SECRET,\n",
    "        \"scope\": FT_SCOPE,\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            r = requests.post(url, data=data)\n",
    "            r.raise_for_status()\n",
    "            return r.json()[\"access_token\"]\n",
    "        except requests.RequestException as e:\n",
    "            logging.warning(f\"Erreur OAuth attempt {attempt+1}: {e}\")\n",
    "            time.sleep(wait)\n",
    "    raise RuntimeError(\"Impossible d'obtenir un token OAuth apr√®s plusieurs essais.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ec349-fdb2-4e83-9f7f-da83e1e12a31",
   "metadata": {},
   "source": [
    "### Lancement requ√™te API France Travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e82e7838-3f2b-4058-95fe-465efefdbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# API CALL FRANCE TRAVAIL\n",
    "# ---------------------------\n",
    "def fetch_france_travail_jobs(query, token, max_pages=MAX_PAGES):\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    try:        \n",
    "        all_jobs = []\n",
    "        b_stop_criteria = False\n",
    "        \n",
    "        for page in range(1, max_pages + 1):\n",
    "            if b_stop_criteria == False:    \n",
    "                url = f\"https://api.francetravail.io/partenaire/offresdemploi/v2/offres/search\"\n",
    "                params = {\n",
    "                    \"motsCles\": query,\n",
    "                    \"commune\": COMMUNE,\n",
    "                    \"distance\" : DISTANCE,\n",
    "                    \"range\": f\"{(page-1)*BLOC_PAGINATION}-{page*BLOC_PAGINATION-1}\"  # pagination par blocs de 50\n",
    "                }\n",
    "                r = requests.get(url, headers=headers, params=params)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                offres = data.get(\"resultats\", [])\n",
    "                    \n",
    "                for o in offres:\n",
    "                    all_jobs.append({\n",
    "                        \"source\": \"France Travail\",\n",
    "                        \"recherche\": f\"{query}\",\n",
    "                        \"id\":o.get(\"id\") if o.get(\"id\") is not None else \"None\",    \n",
    "                        \"titre\": o.get(\"intitule\") if o.get(\"intitule\") is not None else \"None\",                     \n",
    "                        \"description\": o.get(\"description\") if o.get(\"description\") is not None else \"None\", \n",
    "                        \"entreprise\": o.get(\"entreprise\", {}).get(\"nom\") if o.get(\"entreprise\", {}).get(\"nom\") is not None else \"None\", \n",
    "                        \"lieu\": o.get(\"lieuTravail\", {}).get(\"libelle\") if o.get(\"lieuTravail\", {}).get(\"libelle\") is not None else \"None\", \n",
    "                        \"latitude\": o.get(\"lieuTravail\", {}).get(\"latitude\") if o.get(\"lieuTravail\", {}) is not None else \"None\", \n",
    "                        \"longitude\": o.get(\"lieuTravail\", {}).get(\"longitude\") if o.get(\"lieuTravail\", {}) is not None else \"None\", \n",
    "                        \"type_contrat_libelle\": o.get(\"typeContratLibelle\") if o.get(\"typeContratLibelle\") is not None else \"None\", \n",
    "                        \"date_publication\": o.get(\"dateCreation\") if o.get(\"dateCreation\") is not None else \"None\",    \n",
    "                        \"url\": o.get(\"origineOffre\").get(\"urlOrigine\") if o.get(\"origineOffre\") is not None else \"None\",\n",
    "                        \"secteur_activites\": o.get(\"secteurActiviteLibelle\") if o.get(\"dateCreation\") is not None else \"None\"\n",
    "                    })\n",
    "    \n",
    "                # Si le nombre d'offres est inf√©rieur au nombre max d'offre par pages, c'est un signe qu'il n'y a plus d'offres √† extraire apr√®s la page actuelle.\n",
    "                if len(offres) < BLOC_PAGINATION:\n",
    "                    b_stop_criteria = True\n",
    "                \n",
    "        return all_jobs\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Erreur API France Travail: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72571e96-ca0e-4d62-abd1-133db680980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------\n",
    "# # API CALL FRANCE TRAVAIL\n",
    "# # ---------------------------\n",
    "# def fetch_france_travail_jobs(token, max_pages=MAX_PAGES):\n",
    "#     headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "#     try:        \n",
    "#         all_jobs = []\n",
    "#         b_stop_criteria = False\n",
    "        \n",
    "#         for page in range(1, max_pages + 1):\n",
    "#             if b_stop_criteria == False:    \n",
    "#                 url = f\"https://api.francetravail.io/partenaire/offresdemploi/v2/offres/search\"\n",
    "#                 params = {\n",
    "#                     \"motsCles\": JOB_QUERY,\n",
    "#                     \"commune\": COMMUNE,\n",
    "#                     \"distance\" : DISTANCE,\n",
    "#                     \"range\": f\"{(page-1)*BLOC_PAGINATION}-{page*BLOC_PAGINATION-1}\"  # pagination par blocs de 50\n",
    "#                 }\n",
    "#                 r = requests.get(url, headers=headers, params=params)\n",
    "#                 r.raise_for_status()\n",
    "#                 data = r.json()\n",
    "#                 offres = data.get(\"resultats\", [])\n",
    "                    \n",
    "#                 for o in offres:\n",
    "#                     all_jobs.append({\n",
    "#                         \"source\": \"France Travail\",\n",
    "#                         \"recherche\": f\"{JOB_QUERY}\",\n",
    "#                         \"id\":o.get(\"id\") if o.get(\"id\") is not None else \"None\",    \n",
    "#                         \"titre\": o.get(\"intitule\") if o.get(\"intitule\") is not None else \"None\",                     \n",
    "#                         \"description\": o.get(\"description\") if o.get(\"description\") is not None else \"None\", \n",
    "#                         \"entreprise\": o.get(\"entreprise\", {}).get(\"nom\") if o.get(\"entreprise\", {}).get(\"nom\") is not None else \"None\", \n",
    "#                         \"lieu\": o.get(\"lieuTravail\", {}).get(\"libelle\") if o.get(\"lieuTravail\", {}).get(\"libelle\") is not None else \"None\", \n",
    "#                         \"latitude\": o.get(\"lieuTravail\", {}).get(\"latitude\") if o.get(\"lieuTravail\", {}) is not None else \"None\", \n",
    "#                         \"longitude\": o.get(\"lieuTravail\", {}).get(\"longitude\") if o.get(\"lieuTravail\", {}) is not None else \"None\", \n",
    "#                         \"type_contrat_libelle\": o.get(\"typeContratLibelle\") if o.get(\"typeContratLibelle\") is not None else \"None\", \n",
    "#                         \"date_publication\": o.get(\"dateCreation\") if o.get(\"dateCreation\") is not None else \"None\",    \n",
    "#                         \"url\": o.get(\"origineOffre\").get(\"urlOrigine\") if o.get(\"origineOffre\") is not None else \"None\",\n",
    "#                         \"secteur_activites\": o.get(\"secteurActiviteLibelle\") if o.get(\"dateCreation\") is not None else \"None\"\n",
    "#                     })\n",
    "    \n",
    "#                 # Si le nombre d'offres est inf√©rieur au nombre max d'offre par pages, c'est un signe qu'il n'y a plus d'offres √† extraire apr√®s la page actuelle.\n",
    "#                 if len(offres) < BLOC_PAGINATION:\n",
    "#                     b_stop_criteria = True\n",
    "                \n",
    "#         return all_jobs\n",
    "#     except requests.RequestException as e:\n",
    "#         logging.error(f\"Erreur API France Travail: {e}\")\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c384c3db-adb2-4c05-96c2-5f75fd670fd9",
   "metadata": {},
   "source": [
    "### Lancement de requ√™te Adzuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86633fe9-b12a-4e55-9a0a-e63ccba9d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# API CALL ADZUNA\n",
    "# ---------------------------\n",
    "def fetch_adzuna_jobs(query, max_pages=MAX_PAGES):\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    try:        \n",
    "        all_jobs = []\n",
    "        b_stop_criteria = False\n",
    "        \n",
    "        for page in range(1, max_pages + 1):\n",
    "            if b_stop_criteria == False:    \n",
    "                url = f\"https://api.adzuna.com/v1/api/jobs/fr/search/{page}\"\n",
    "                params = {\n",
    "                    \"app_id\" : ADZUNA_CLIENT_ID,\n",
    "                    \"app_key\" : ADZUNA_CLIENT_SECRET,\n",
    "                    \"title_only\": query,\n",
    "                    \"where\": COMMUNE,\n",
    "                    \"results_per_page\" : BLOC_PAGINATION,\n",
    "                    \"distance\" : DISTANCE\n",
    "                }\n",
    "                r = requests.get(url,params=params)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                offres = data.get(\"results\")\n",
    "    \n",
    "                for o in offres:\n",
    "                    all_jobs.append({\n",
    "                        \"source\": \"Adzuna\",\n",
    "                        \"recherche\":f\"{query}\",\n",
    "                        \"id\" : o.get(\"id\") if o.get(\"id\") is not None else \"None\", \n",
    "                        \"titre\" : o.get(\"title\") if o.get(\"title\") is not None else \"None\", \n",
    "                        \"description\" : o.get(\"description\") if o.get(\"description\") is not None else \"None\", \n",
    "                        \"entreprise\": o.get(\"company\").get(\"display_name\") if o.get(\"company\") is not None else \"None\",\n",
    "                        \"lieu\" : o.get(\"location\").get(\"display_name\") if o.get(\"location\") is not None else \"None\",    \n",
    "                        \"latitude\" : o.get(\"latitude\") if o.get(\"latitude\") is not None else \"None\", \n",
    "                        \"longitude\" : o.get(\"longitude\") if o.get(\"longitude\") is not None else \"None\",\n",
    "                        \"type_contrat_libelle\" : o.get(\"contract_type\") if o.get(\"contract_type\") is not None else \"None\",                \n",
    "                        \"date_publication\" : o.get(\"created\") if o.get(\"created\") is not None else \"None\",  \n",
    "                        \"url\" : o.get(\"redirect_url\") if o.get(\"redirect_url\") is not None else \"None\",  \n",
    "                        \"secteur_activites\" : o.get(\"category\").get(\"label\") if o.get(\"category\") is not None else \"None\",\n",
    "                    })\n",
    "                    \n",
    "                # Si le nombre d'offres est inf√©rieur au nombre max d'offre par pages, c'est un signe qu'il n'y a plus d'offres √† extraire apr√®s la page actuelle.\n",
    "                if len(offres) < BLOC_PAGINATION:\n",
    "                    b_stop_criteria = True\n",
    "                \n",
    "        return all_jobs\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Erreur API Adzuna: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70ba44d7-41f8-4af8-9254-f443a6e307fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------\n",
    "# # API CALL ADZUNA\n",
    "# # ---------------------------\n",
    "# def fetch_adzuna_jobs(max_pages=MAX_PAGES):\n",
    "#     headers = {\"Accept\": \"application/json\"}\n",
    "#     try:        \n",
    "#         all_jobs = []\n",
    "#         b_stop_criteria = False\n",
    "        \n",
    "#         for page in range(1, max_pages + 1):\n",
    "#             if b_stop_criteria == False:    \n",
    "#                 url = f\"https://api.adzuna.com/v1/api/jobs/fr/search/{page}\"\n",
    "#                 params = {\n",
    "#                     \"app_id\" : ADZUNA_CLIENT_ID,\n",
    "#                     \"app_key\" : ADZUNA_CLIENT_SECRET,\n",
    "#                     \"title_only\": JOB_QUERY,\n",
    "#                     \"where\": COMMUNE,\n",
    "#                     \"results_per_page\" : BLOC_PAGINATION,\n",
    "#                     \"distance\" : DISTANCE\n",
    "#                 }\n",
    "#                 r = requests.get(url,params=params)\n",
    "#                 r.raise_for_status()\n",
    "#                 data = r.json()\n",
    "#                 offres = data.get(\"results\")\n",
    "    \n",
    "#                 for o in offres:\n",
    "#                     all_jobs.append({\n",
    "#                         \"source\": \"Adzuna\",\n",
    "#                         \"recherche\":f\"{JOB_QUERY}\",\n",
    "#                         \"id\" : o.get(\"id\") if o.get(\"id\") is not None else \"None\", \n",
    "#                         \"titre\" : o.get(\"title\") if o.get(\"title\") is not None else \"None\", \n",
    "#                         \"description\" : o.get(\"description\") if o.get(\"description\") is not None else \"None\", \n",
    "#                         \"entreprise\": o.get(\"company\").get(\"display_name\") if o.get(\"company\") is not None else \"None\",\n",
    "#                         \"lieu\" : o.get(\"location\").get(\"display_name\") if o.get(\"location\") is not None else \"None\",    \n",
    "#                         \"latitude\" : o.get(\"latitude\") if o.get(\"latitude\") is not None else \"None\", \n",
    "#                         \"longitude\" : o.get(\"longitude\") if o.get(\"longitude\") is not None else \"None\",\n",
    "#                         \"type_contrat_libelle\" : o.get(\"contract_type\") if o.get(\"contract_type\") is not None else \"None\",                \n",
    "#                         \"date_publication\" : o.get(\"created\") if o.get(\"created\") is not None else \"None\",  \n",
    "#                         \"url\" : o.get(\"redirect_url\") if o.get(\"redirect_url\") is not None else \"None\",  \n",
    "#                         \"secteur_activites\" : o.get(\"category\").get(\"label\") if o.get(\"category\") is not None else \"None\",\n",
    "#                     })\n",
    "                    \n",
    "#                 # Si le nombre d'offres est inf√©rieur au nombre max d'offre par pages, c'est un signe qu'il n'y a plus d'offres √† extraire apr√®s la page actuelle.\n",
    "#                 if len(offres) < BLOC_PAGINATION:\n",
    "#                     b_stop_criteria = True\n",
    "                \n",
    "#         return all_jobs\n",
    "#     except requests.RequestException as e:\n",
    "#         logging.error(f\"Erreur API Adzuna: {e}\")\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6429abb-111d-4a7a-a1bf-9ad698540ffd",
   "metadata": {},
   "source": [
    "### D√©duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98da7cdb-9465-4684-957e-041bfe9c26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# D√âDUPLICATION\n",
    "# ---------------------------\n",
    "def deduplicate(jobs):\n",
    "    seen = set()\n",
    "    deduped = []\n",
    "    for job in jobs:\n",
    "        key_str = f\"{job['titre']}_{job['entreprise']}_{job['latitude']}_{job['longitude']}_{job['date_publication']}\"\n",
    "        key = hashlib.md5(key_str.encode()).hexdigest()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            deduped.append(job)\n",
    "    return deduped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4e04e-f305-4a2a-a890-6fe42ce0437d",
   "metadata": {},
   "source": [
    "### Ajout infos localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9be28c71-a049-4af5-84a0-1eb63da04cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# RECHERCHE INFOS LOCALISATION SUPPLEMENTAIRES (commune, code_postal, departement)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def get_localization_info(df):    \n",
    "    PATH_COMMUNES = \"../data/raw_data/location_data/COMMUNE_FRMETDROM.shp\"\n",
    "    \n",
    "    # Extract ccoordon√©es GPS\n",
    "    coord = df[['longitude','latitude']]\n",
    "    \n",
    "    # Transformer en GeoDataFrame (EPSG:4326 = WGS84 = lat/lon)\n",
    "    gdf_points = gpd.GeoDataFrame(\n",
    "        coord,\n",
    "        geometry=[Point(xy) for xy in zip(coord.longitude, coord.latitude)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Charger le shapefile des communes\n",
    "    communes = gpd.read_file(PATH_COMMUNES).to_crs(epsg=4326)\n",
    "\n",
    "    # Jointure spatiale\n",
    "    result = gpd.sjoin(gdf_points, communes, how=\"left\", predicate=\"within\")\n",
    "\n",
    "    # Garder les colonnes utiles\n",
    "    final = result[[\"NOM_M\", \n",
    "                    \"INSEE_COM\", \n",
    "                    \"INSEE_DEP\"]].rename(columns = {\"NOM_M\":\"commune\",\n",
    "                                                    \"INSEE_COM\":\"code_postal\",\n",
    "                                                    \"INSEE_DEP\":\"departement\"})\n",
    "\n",
    "    return pd.merge(df, final, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b7935-0d6b-4bef-9c72-ec09ccc7d2ac",
   "metadata": {},
   "source": [
    "### Nettoyage de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1434de4-10d9-4ba1-b4d1-1dee055bb332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e9db3-fa0a-4457-81df-f6bb52f2b2bc",
   "metadata": {},
   "source": [
    "### Calcul embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f85ae768-d6d1-4cc5-be64-8363f54210ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(text):\n",
    "    return model.encode([text], convert_to_numpy=True,show_progress_bar=False)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94663b-d5f9-467c-98c1-0b7cd1c26705",
   "metadata": {},
   "source": [
    "### Initialisation database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad547c1c-d524-4cad-8bbf-67afaafddb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialisation DB ---\n",
    "# SUPPRESSION DE Date_creation TIMESTAMP\n",
    "def init_db(engine):\n",
    "    with engine.begin() as conn:\n",
    "        \n",
    "        # Activer l'extension PGVector\n",
    "        conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector;\"))\n",
    "\n",
    "        # Cr√©er la table\n",
    "        conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS offres (\n",
    "            id TEXT PRIMARY KEY,\n",
    "            source TEXT,\n",
    "            recherche TEXT,\n",
    "            titre TEXT,\n",
    "            description TEXT,\n",
    "            entreprise TEXT,\n",
    "            lieu TEXT,\n",
    "            latitude FLOAT(4),\n",
    "            longitude FLOAT(4),\n",
    "            commune TEXT,\n",
    "            code_postal TEXT,\n",
    "            departement TEXT,\n",
    "            type_contrat_libelle TEXT,\n",
    "            date_publication DATE,\n",
    "            url TEXT,\n",
    "            secteur_activites TEXT,\n",
    "            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            embedding vector(384)  -- dimension MiniLM\n",
    "        )\n",
    "        \"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec24a33-1dd6-4d65-9d05-ad203954dbc0",
   "metadata": {},
   "source": [
    "### Sauvegarde en base PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4f8714f-8ab5-43c6-8e03-98bce597c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_postgres_upsert(df, engine, table_name=\"offres\"):\n",
    "    \"\"\"\n",
    "    Sauvegarde un DataFrame pandas dans PostgreSQL avec UPSERT.\n",
    "    Met √† jour last_updated pour chaque ligne ins√©r√©e ou modifi√©e.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): donn√©es √† ins√©rer\n",
    "        engine (sqlalchemy.Engine): moteur SQLAlchemy connect√© √† PostgreSQL\n",
    "        table_name (str): nom de la table cible\n",
    "    \n",
    "    Returns:\n",
    "        int: nombre de lignes ins√©r√©es ou mises √† jour\n",
    "    \"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        logging.info(\"üì≠ DataFrame vide, rien √† ins√©rer.\")\n",
    "        return 0\n",
    "\n",
    "    # Nettoyage des NaN\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    metadata = MetaData()\n",
    "    table = Table(table_name, metadata, autoload_with=engine)\n",
    "    now = datetime.utcnow()\n",
    "    count = 0\n",
    "\n",
    "    try:        \n",
    "        with engine.begin() as conn:\n",
    "            for row in df.to_dict(orient=\"records\"):\n",
    "                row[\"last_updated\"] = now\n",
    "                \n",
    "                # Calcul embedding uniquement si nouvelle offre\n",
    "                if not row.get(\"embedding\"):\n",
    "                    row[\"embedding\"] = compute_embedding(row[\"description\"])\n",
    "                    \n",
    "                stmt = pg_insert(table).values(row)\n",
    "                stmt = stmt.on_conflict_do_update(\n",
    "                    index_elements=['id'],\n",
    "                    set_={\n",
    "                        'source': stmt.excluded.source,\n",
    "                        'recherche':stmt.excluded.recherche,\n",
    "                        'titre': stmt.excluded.titre,\n",
    "                        'description': stmt.excluded.description,\n",
    "                        'entreprise': stmt.excluded.entreprise,\n",
    "                        'lieu': stmt.excluded.lieu,\n",
    "                        'latitude': stmt.excluded.latitude,\n",
    "                        'longitude': stmt.excluded.longitude,   \n",
    "                        'commune': stmt.excluded.commune,   \n",
    "                        'code_postal': stmt.excluded.code_postal,   \n",
    "                        'departement': stmt.excluded.departement,                 \n",
    "                        'type_contrat_libelle': stmt.excluded.type_contrat_libelle,\n",
    "                        'date_publication': stmt.excluded.date_publication,\n",
    "                        'url': stmt.excluded.url,\n",
    "                        'secteur_activites': stmt.excluded.secteur_activites,\n",
    "                        # forc√© √† chaque ex√©cution, m√™me sans changement d'autres colonnes\n",
    "                        'last_updated': now,\n",
    "                        'embedding': stmt.excluded.embedding\n",
    "                    }\n",
    "                )\n",
    "                conn.execute(stmt)\n",
    "                count += 1\n",
    "        logging.info(f\"{count} offres ins√©r√©es/mises √† jour dans PostgreSQL.\")\n",
    "        return count\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        logging.error(f\"‚ùå Erreur lors de l'UPSERT : {str(e)}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac263cb7-f4a0-417f-851c-f2690e689095",
   "metadata": {},
   "source": [
    "### Calcul similarit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f9b0410-dbbc-4748-92c2-ced809ec187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_offres_all(reference_text, engine):\n",
    "    ref_emb = compute_embedding(reference_text)\n",
    "    ref_emb_str = \"[\" + \",\".join(map(str, ref_emb)) + \"]\"  # convertir en string pour PGVector\n",
    "\n",
    "    query = text(\"\"\"\n",
    "        SELECT  \n",
    "                id, source, recherche, titre, description, entreprise,\n",
    "                lieu, latitude, longitude,commune, code_postal,departement,\n",
    "                type_contrat_libelle, date_publication, url, secteur_activites,\n",
    "                last_updated, embedding, simil\n",
    "        FROM (\n",
    "            SELECT \n",
    "                    id, source, recherche, titre, description, entreprise,\n",
    "                    lieu, latitude, longitude,commune, code_postal,departement,\n",
    "                    type_contrat_libelle, date_publication, url, secteur_activites,\n",
    "                    last_updated, embedding,\n",
    "                    1 - (embedding <#> (:ref)::vector) AS simil\n",
    "            FROM offres\n",
    "        ) AS s\n",
    "        ORDER BY simil DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {\"ref\": ref_emb_str})       \n",
    "        return pd.DataFrame(result.fetchall(),columns=[\"id\", \"source\", \"recherche\", \"titre\", \n",
    "                                                       \"description\", \"entreprise\",\"lieu\",\n",
    "                                                       \"latitude\", \"longitude\",\"commune\", \n",
    "                                                       \"code_postal\",\"departement\",\n",
    "                                                       \"type_contrat_libelle\", \"date_publication\",\n",
    "                                                       \"url\", \"secteur_activites\",\"last_updated\",\n",
    "                                                       \"embedding\", \"simil\"]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75112a-913c-4cc2-bdfd-f5a320ac2e9d",
   "metadata": {},
   "source": [
    "### Sauvegarde CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75d0bd1a-552d-4f1a-a5d5-6c71331c54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sauvegarde Parquet ---\n",
    "def save_to_csv(df, csv_directory, filename):\n",
    "    if df.empty:\n",
    "        return\n",
    "    os.makedirs(csv_directory, exist_ok=True)\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    path_csv = os.path.join(csv_directory, f\"{today}_{filename}.csv\")\n",
    "    df.to_csv(path_csv, index=False,encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ Sauvegard√© dans {path_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c69b5-e661-49b9-be53-abe6835a3a74",
   "metadata": {},
   "source": [
    "### Sauvegarde Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b972c51-3307-49aa-a409-21b662763b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sauvegarde Parquet ---\n",
    "def save_to_parquet(df,parquet_directory, filename):\n",
    "    if df.empty:\n",
    "        return\n",
    "    os.makedirs(parquet_directory, exist_ok=True)\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    path_parquet = os.path.join(parquet_directory, f\"{today}_{filename}.parquet\")\n",
    "    df.to_parquet(path_parquet, index=False)\n",
    "    print(f\"‚úÖ Sauvegard√© dans {path_parquet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14139dd5-4bb0-445d-bd53-56bbb4dfffe0",
   "metadata": {},
   "source": [
    "### Sauvegarde Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "532f27d3-465d-4937-88cd-decd76bf6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sauvegarde Excel --- \n",
    "def save_to_excel(df,excel_directory, filename):\n",
    "    if df.empty:\n",
    "        return\n",
    "    os.makedirs(excel_directory, exist_ok=True)\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    path_excel = os.path.join(excel_directory, f\"{today}_{filename}.xlsx\")\n",
    "    df.to_excel(path_excel, index=False)\n",
    "    print(f\"‚úÖ Sauvegard√© dans {path_excel}\")\n",
    "    return path_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f5499-2879-4fd3-ba43-9ee1bdeac808",
   "metadata": {},
   "source": [
    "### Mise √† jour du fichier de suivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b38b8736-ad19-4600-ba7b-218a8d31955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tracking_file(new_export_path, tracking_file_path_dir, output_path_dir, filename):   \n",
    "    # tracking_cols = [\"date_candidature\", \"nom_cv\", \"date_relance\", \"reponse_recue\"]\n",
    "    tracking_cols= [\"candidature_envisagee\",\"type_contrat\",\"experience_requise\",\n",
    "                    \"date_candidature\", \"date_candidature_jour\", \"date_candidature_mois\", \n",
    "                    \"date_candidature_annee\", \"nom_cv\", \"nom_lm\", \"nom_fichier_offre\",\n",
    "                    \"date_relance_prevue\", \"date_relance_effectuee\", \"reponse_recue\",\n",
    "                    \"date_reponse_entreprise\", \"etape_atteinte\", \"nom_coord_recruteur\",\n",
    "                    \"notes_perso\", \"resultat_final\", \"nb_jours_candidature_reponse\",\n",
    "                    \"nb_jours_candidature_resultat_final\",\"score_adequation_poste_profil\",\n",
    "                    \"priorite_offre\", \"mots_cles_poste\", \"motivation\"]\n",
    "    \n",
    "    # Charger l‚Äôexport quotidien depuis PostgreSQL\n",
    "    new_df = pd.read_excel(new_export_path)\n",
    "\n",
    "    try:\n",
    "        # Charger ton fichier de suivi existant\n",
    "        os.makedirs(tracking_file_path_dir, exist_ok=True)\n",
    "        tracking_file_path = os.path.join(tracking_file_path_dir, f\"{filename}.xlsx\")\n",
    "        tracking_df = pd.read_excel(tracking_file_path)\n",
    "    except FileNotFoundError:\n",
    "        # Si le fichier n‚Äôexiste pas encore, on cr√©e le suivi avec les donn√©es initiales\n",
    "        tracking_df = new_df.copy()\n",
    "        # Ajouter les colonnes manuelles vides\n",
    "        for col in tracking_cols:\n",
    "            tracking_df[col] = None\n",
    "\n",
    "    # Fusionner sur la cl√© 'id'\n",
    "    merged_df = pd.merge(\n",
    "        new_df,\n",
    "        tracking_df,\n",
    "        on=\"id\",\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"\", \"_old\")\n",
    "    )\n",
    "    \n",
    "    # Conserver les colonnes manuelles de l‚Äôancien suivi\n",
    "    for col in new_df.columns.values.tolist() + tracking_cols:\n",
    "        if f\"{col}_old\" in merged_df.columns:\n",
    "            merged_df[col] = merged_df[col].combine_first(merged_df[f\"{col}_old\"])\n",
    "            merged_df.drop(columns=[f\"{col}_old\"], inplace=True)\n",
    "    \n",
    "    # Sauvegarder le fichier mis √† jour\n",
    "    save_to_excel(merged_df,output_path_dir, filename)\n",
    "    \n",
    "    print(f\"‚úÖ Fichier de suivi mis √† jour dans : {output_path_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdda02-d6b6-40a2-bfac-934fc24cf646",
   "metadata": {},
   "source": [
    "### Pipeline principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb6f8148-0086-47ea-b620-5d32c006c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- PIPELINE ----------------\n",
    "def run_pipeline(query):\n",
    "    logging.info(\"D√©but du pipeline.\")\n",
    "\n",
    "    try:        \n",
    "        print(\"Authentification France Travail...\")\n",
    "        token = get_ft_token()\n",
    "    \n",
    "        print(\"R√©cup√©ration des offres France Travail...\")\n",
    "        ft_jobs = fetch_france_travail_jobs(query, token)\n",
    "    \n",
    "        print(\"R√©cup√©ration des offres Adzuna...\")\n",
    "        adzuna_jobs = fetch_adzuna_jobs(query)\n",
    "    \n",
    "        print(\"Fusion et d√©duplication...\")\n",
    "        all_jobs = ft_jobs + adzuna_jobs\n",
    "    \n",
    "        if not all_jobs:\n",
    "            print(\"‚ö†Ô∏è Aucune offre trouv√©e.\")\n",
    "            return\n",
    "    \n",
    "        print(f\"Nombre d'offres d'emploi avant d√©duplication : {len(all_jobs)}\")\n",
    "        jobs_clean = deduplicate(all_jobs)\n",
    "        print(f\"Nombre d'offres d'emploi apr√®s d√©duplication : {len(jobs_clean)}\")\n",
    "    \n",
    "        print(\"Affichage des offres...\")\n",
    "        df = pd.DataFrame(jobs_clean)\n",
    "\n",
    "        print(\"Ajout commune, code_postal et departement...\")\n",
    "        df = get_localization_info(df)\n",
    "        \n",
    "        # # Export vers CSV\n",
    "        # print(\"üíæ Sauvegarde en CSV...\")\n",
    "        # save_to_csv(df, CSV_DIR_RAW,'offres_brutes')\n",
    "    \n",
    "        # # Export vers Parquet\n",
    "        # print(\"üíæ Sauvegarde en Parquet...\")\n",
    "        # save_to_parquet(df, PARQUET_DIR_RAW,'offres_brutes')\n",
    "        \n",
    "        print(f\"{len(jobs_clean)} offres uniques export√©es dans {CSV_DIR_RAW} et {PARQUET_DIR_RAW} ‚úÖ\")\n",
    "    \n",
    "        # Connexion DB\n",
    "        print(\"Connexion √† la base PostgreSQL...\")\n",
    "        engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "    \n",
    "        # Initier la bdd\n",
    "        init_db(engine)\n",
    "    \n",
    "        print(\"üíæ Sauvegarde en base PostgreSQL...\")\n",
    "        save_to_postgres_upsert(df, engine, table_name=DB_TABLE_NAME)\n",
    "        print(\"üíæ Sauvegarde en base PostgreSQL TERMINEE !!!...\")\n",
    "\n",
    "        # Recherche top offres similaires\n",
    "        print(\"Lancement requ√™te en similarit√© ...\")\n",
    "        top_offres = search_similar_offres_all(reference_text_clean,engine)\n",
    "        logging.info(f\"Top 10 offres les plus proches:\\n{top_offres}\")\n",
    "        logging.info(\"Pipeline termin√© avec succ√®s.\")\n",
    "\n",
    "        # # Export vers CSV\n",
    "        # print(\"üíæ Sauvegarde en CSV (avec Similarit√©)...\")\n",
    "        # save_to_csv(top_offres, CSV_DIR_PROC,'offres_similarite')\n",
    "    \n",
    "        # # Export vers Parquet\n",
    "        # print(\"üíæ Sauvegarde en Parquet (avec Similarit√©)...\")\n",
    "        # save_to_parquet(top_offres, PARQUET_DIR_PROC,'offres_similarite')\n",
    "\n",
    "        # Export vers Excel\n",
    "        print(\"üíæ Sauvegarde en Excel (avec Similarit√©)...\")\n",
    "        similarity_excel_path = save_to_excel(top_offres, EXCEL_DIR_PROC,'offres_similarite')\n",
    "\n",
    "        # Mise √† jour du fichier de suivi vers Excel\n",
    "        print(\"Mise √† jour du fichier de suivi...\")\n",
    "        tracking_filename = \"suivi_candidatures\"\n",
    "        tracking_file_path_dir=f\"../data/processed_data/suivi_candidature/input_tracking_file\"\n",
    "        output_path_dir=f\"../data/processed_data/suivi_candidature/output_tracking_file\"        \n",
    "        update_tracking_file(\n",
    "                                similarity_excel_path,\n",
    "                                tracking_file_path_dir,\n",
    "                                output_path_dir,\n",
    "                                tracking_filename,\n",
    "                            )\n",
    "    \n",
    "        # Affichage extract offres\n",
    "        display(top_offres.shape)\n",
    "        display(top_offres.head())\n",
    "\n",
    "        # # Affichage extract offres\n",
    "        # display(df.shape)\n",
    "        # display(df.head(3))\n",
    "\n",
    "        print(\"FIN DU SCRIPT !!!...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Pipeline √©chou√©: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2de560b5-c04e-4118-9662-7069e1da4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chargement depuis CSV\n",
    "# today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# path_parquet = os.path.join(PARQUET_DIR, f\"{today}_offres.parquet\")\n",
    "# df = pd.read_parquet(path_parquet)\n",
    "# display(df.shape)\n",
    "# display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859727e-da41-42a1-9772-fa2708d9d558",
   "metadata": {},
   "source": [
    "### Proc√©dure principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff03fb25-913a-46ea-a784-b7f5f54e9f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentification France Travail...\n",
      "R√©cup√©ration des offres France Travail...\n",
      "R√©cup√©ration des offres Adzuna...\n",
      "Fusion et d√©duplication...\n",
      "Nombre d'offres d'emploi avant d√©duplication : 994\n",
      "Nombre d'offres d'emploi apr√®s d√©duplication : 992\n",
      "Affichage des offres...\n",
      "Ajout commune, code_postal et departement...\n",
      "992 offres uniques export√©es dans ../data/raw_data/csv et ../data/raw_data/parquet ‚úÖ\n",
      "Connexion √† la base PostgreSQL...\n",
      "üíæ Sauvegarde en base PostgreSQL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2040/2012227555.py:23: SAWarning: Did not recognize type 'vector' of column 'embedding'\n",
      "  table = Table(table_name, metadata, autoload_with=engine)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Sauvegarde en base PostgreSQL TERMINEE !!!...\n",
      "Lancement requ√™te en similarit√© ...\n",
      "üíæ Sauvegarde en Excel (avec Similarit√©)...\n",
      "‚úÖ Sauvegard√© dans ../data/processed_data/excel/2025-09-19_19-30-22_offres_similarite.xlsx\n",
      "Mise √† jour du fichier de suivi...\n",
      "‚úÖ Sauvegard√© dans ../data/processed_data/suivi_candidature/output_tracking_file/2025-09-19_19-30-24_suivi_candidatures.xlsx\n",
      "‚úÖ Fichier de suivi mis √† jour dans : ../data/processed_data/suivi_candidature/output_tracking_file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1954, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>recherche</th>\n",
       "      <th>titre</th>\n",
       "      <th>description</th>\n",
       "      <th>entreprise</th>\n",
       "      <th>lieu</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>commune</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>departement</th>\n",
       "      <th>type_contrat_libelle</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>url</th>\n",
       "      <th>secteur_activites</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>embedding</th>\n",
       "      <th>simil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8653579</td>\n",
       "      <td>France Travail</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Data Analyst Smart Pricing (F/H) (H/F)</td>\n",
       "      <td>Data Analyst Smart Pricing (F/H) Enregistrer p...</td>\n",
       "      <td>None</td>\n",
       "      <td>93 - AUBERVILLIERS</td>\n",
       "      <td>48.91456</td>\n",
       "      <td>2.381792</td>\n",
       "      <td>AUBERVILLIERS</td>\n",
       "      <td>93001</td>\n",
       "      <td>93</td>\n",
       "      <td>Contrat √† dur√©e ind√©termin√©e</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>https://candidat.francetravail.fr/offres/reche...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-19 10:46:31.945979</td>\n",
       "      <td>[-0.45374092,0.250378,-0.28020337,-0.29035896,...</td>\n",
       "      <td>6.131842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5378713497</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Data Scientist/ Python/ Looker / GCP/ VerteX A...</td>\n",
       "      <td>Nous recherchons pour le compte de notre clien...</td>\n",
       "      <td>Octopus Group</td>\n",
       "      <td>Ivry-sur-Seine, Cr√©teil</td>\n",
       "      <td>48.80780</td>\n",
       "      <td>2.374620</td>\n",
       "      <td>IVRY-SUR-SEINE</td>\n",
       "      <td>94041</td>\n",
       "      <td>94</td>\n",
       "      <td>contract</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>https://www.adzuna.fr/details/5378713497?utm_m...</td>\n",
       "      <td>Emplois Informatique</td>\n",
       "      <td>2025-09-19 17:23:02.086287</td>\n",
       "      <td>[-0.18336365,0.04164475,-0.20463689,-0.2488077...</td>\n",
       "      <td>5.747982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5381030408</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Lead Data Scientist/ Python/ Looker / GCP/ Ver...</td>\n",
       "      <td>Nous recherchons pour le compte de notre clien...</td>\n",
       "      <td>Octopus Group</td>\n",
       "      <td>Ivry-sur-Seine, Cr√©teil</td>\n",
       "      <td>48.80780</td>\n",
       "      <td>2.374620</td>\n",
       "      <td>IVRY-SUR-SEINE</td>\n",
       "      <td>94041</td>\n",
       "      <td>94</td>\n",
       "      <td>contract</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>https://www.adzuna.fr/details/5381030408?utm_m...</td>\n",
       "      <td>Emplois Informatique</td>\n",
       "      <td>2025-09-19 17:23:02.086287</td>\n",
       "      <td>[-0.18336365,0.04164475,-0.20463689,-0.2488077...</td>\n",
       "      <td>5.747982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5380688338</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Data Analyst Senior H/F</td>\n",
       "      <td>Nous recherchons un Data Analyst Senior pour a...</td>\n",
       "      <td>Ekkiden</td>\n",
       "      <td>La-Madeleine, Lille</td>\n",
       "      <td>50.63718</td>\n",
       "      <td>3.063020</td>\n",
       "      <td>LILLE</td>\n",
       "      <td>59350</td>\n",
       "      <td>59</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>https://www.adzuna.fr/details/5380688338?utm_m...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-09-19 17:28:45.671088</td>\n",
       "      <td>[-0.33283094,0.26524156,-0.10381974,-0.2060563...</td>\n",
       "      <td>5.664216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5387798041</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Alternant Data Analyst H/F</td>\n",
       "      <td>Dans le cadre du d√©veloppement de nos activit√©...</td>\n",
       "      <td>Exco</td>\n",
       "      <td>Paris, Ile-de-France</td>\n",
       "      <td>48.86384</td>\n",
       "      <td>2.344631</td>\n",
       "      <td>PARIS 1ER ARRONDISSEMENT</td>\n",
       "      <td>75101</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.adzuna.fr/details/5387798041?utm_m...</td>\n",
       "      <td>Emplois Autres/G√©n√©ral</td>\n",
       "      <td>2025-09-19 17:28:45.671088</td>\n",
       "      <td>[-0.2326749,0.03829508,-0.12620185,-0.16146821...</td>\n",
       "      <td>5.605638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          source       recherche  \\\n",
       "0     8653579  France Travail    data analyst   \n",
       "1  5378713497          Adzuna  data scientist   \n",
       "2  5381030408          Adzuna  data scientist   \n",
       "3  5380688338          Adzuna    data analyst   \n",
       "4  5387798041          Adzuna    data analyst   \n",
       "\n",
       "                                               titre  \\\n",
       "0             Data Analyst Smart Pricing (F/H) (H/F)   \n",
       "1  Data Scientist/ Python/ Looker / GCP/ VerteX A...   \n",
       "2  Lead Data Scientist/ Python/ Looker / GCP/ Ver...   \n",
       "3                            Data Analyst Senior H/F   \n",
       "4                         Alternant Data Analyst H/F   \n",
       "\n",
       "                                         description     entreprise  \\\n",
       "0  Data Analyst Smart Pricing (F/H) Enregistrer p...           None   \n",
       "1  Nous recherchons pour le compte de notre clien...  Octopus Group   \n",
       "2  Nous recherchons pour le compte de notre clien...  Octopus Group   \n",
       "3  Nous recherchons un Data Analyst Senior pour a...        Ekkiden   \n",
       "4  Dans le cadre du d√©veloppement de nos activit√©...           Exco   \n",
       "\n",
       "                      lieu  latitude  longitude                   commune  \\\n",
       "0       93 - AUBERVILLIERS  48.91456   2.381792             AUBERVILLIERS   \n",
       "1  Ivry-sur-Seine, Cr√©teil  48.80780   2.374620            IVRY-SUR-SEINE   \n",
       "2  Ivry-sur-Seine, Cr√©teil  48.80780   2.374620            IVRY-SUR-SEINE   \n",
       "3      La-Madeleine, Lille  50.63718   3.063020                     LILLE   \n",
       "4     Paris, Ile-de-France  48.86384   2.344631  PARIS 1ER ARRONDISSEMENT   \n",
       "\n",
       "  code_postal departement          type_contrat_libelle date_publication  \\\n",
       "0       93001          93  Contrat √† dur√©e ind√©termin√©e       2025-06-24   \n",
       "1       94041          94                      contract       2025-09-02   \n",
       "2       94041          94                      contract       2025-09-03   \n",
       "3       59350          59                          None       2025-09-03   \n",
       "4       75101          75                          None       2025-09-07   \n",
       "\n",
       "                                                 url       secteur_activites  \\\n",
       "0  https://candidat.francetravail.fr/offres/reche...                    None   \n",
       "1  https://www.adzuna.fr/details/5378713497?utm_m...    Emplois Informatique   \n",
       "2  https://www.adzuna.fr/details/5381030408?utm_m...    Emplois Informatique   \n",
       "3  https://www.adzuna.fr/details/5380688338?utm_m...                 Unknown   \n",
       "4  https://www.adzuna.fr/details/5387798041?utm_m...  Emplois Autres/G√©n√©ral   \n",
       "\n",
       "                last_updated  \\\n",
       "0 2025-09-19 10:46:31.945979   \n",
       "1 2025-09-19 17:23:02.086287   \n",
       "2 2025-09-19 17:23:02.086287   \n",
       "3 2025-09-19 17:28:45.671088   \n",
       "4 2025-09-19 17:28:45.671088   \n",
       "\n",
       "                                           embedding     simil  \n",
       "0  [-0.45374092,0.250378,-0.28020337,-0.29035896,...  6.131842  \n",
       "1  [-0.18336365,0.04164475,-0.20463689,-0.2488077...  5.747982  \n",
       "2  [-0.18336365,0.04164475,-0.20463689,-0.2488077...  5.747982  \n",
       "3  [-0.33283094,0.26524156,-0.10381974,-0.2060563...  5.664216  \n",
       "4  [-0.2326749,0.03829508,-0.12620185,-0.16146821...  5.605638  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIN DU SCRIPT !!!...\n",
      "Authentification France Travail...\n",
      "R√©cup√©ration des offres France Travail...\n",
      "R√©cup√©ration des offres Adzuna...\n",
      "Fusion et d√©duplication...\n",
      "Nombre d'offres d'emploi avant d√©duplication : 639\n",
      "Nombre d'offres d'emploi apr√®s d√©duplication : 639\n",
      "Affichage des offres...\n",
      "Ajout commune, code_postal et departement...\n",
      "639 offres uniques export√©es dans ../data/raw_data/csv et ../data/raw_data/parquet ‚úÖ\n",
      "Connexion √† la base PostgreSQL...\n",
      "üíæ Sauvegarde en base PostgreSQL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2040/2012227555.py:23: SAWarning: Did not recognize type 'vector' of column 'embedding'\n",
      "  table = Table(table_name, metadata, autoload_with=engine)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Sauvegarde en base PostgreSQL TERMINEE !!!...\n",
      "Lancement requ√™te en similarit√© ...\n",
      "üíæ Sauvegarde en Excel (avec Similarit√©)...\n",
      "‚úÖ Sauvegard√© dans ../data/processed_data/excel/2025-09-19_19-31-46_offres_similarite.xlsx\n",
      "Mise √† jour du fichier de suivi...\n",
      "‚úÖ Sauvegard√© dans ../data/processed_data/suivi_candidature/output_tracking_file/2025-09-19_19-31-51_suivi_candidatures.xlsx\n",
      "‚úÖ Fichier de suivi mis √† jour dans : ../data/processed_data/suivi_candidature/output_tracking_file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1954, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>recherche</th>\n",
       "      <th>titre</th>\n",
       "      <th>description</th>\n",
       "      <th>entreprise</th>\n",
       "      <th>lieu</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>commune</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>departement</th>\n",
       "      <th>type_contrat_libelle</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>url</th>\n",
       "      <th>secteur_activites</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>embedding</th>\n",
       "      <th>simil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8653579</td>\n",
       "      <td>France Travail</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Data Analyst Smart Pricing (F/H) (H/F)</td>\n",
       "      <td>Data Analyst Smart Pricing (F/H) Enregistrer p...</td>\n",
       "      <td>None</td>\n",
       "      <td>93 - AUBERVILLIERS</td>\n",
       "      <td>48.91456</td>\n",
       "      <td>2.381792</td>\n",
       "      <td>AUBERVILLIERS</td>\n",
       "      <td>93001</td>\n",
       "      <td>93</td>\n",
       "      <td>Contrat √† dur√©e ind√©termin√©e</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>https://candidat.francetravail.fr/offres/reche...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-19 10:46:31.945979</td>\n",
       "      <td>[-0.45374092,0.250378,-0.28020337,-0.29035896,...</td>\n",
       "      <td>6.131842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5378713497</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Data Scientist/ Python/ Looker / GCP/ VerteX A...</td>\n",
       "      <td>Nous recherchons pour le compte de notre clien...</td>\n",
       "      <td>Octopus Group</td>\n",
       "      <td>Ivry-sur-Seine, Cr√©teil</td>\n",
       "      <td>48.80780</td>\n",
       "      <td>2.374620</td>\n",
       "      <td>IVRY-SUR-SEINE</td>\n",
       "      <td>94041</td>\n",
       "      <td>94</td>\n",
       "      <td>contract</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>https://www.adzuna.fr/details/5378713497?utm_m...</td>\n",
       "      <td>Emplois Informatique</td>\n",
       "      <td>2025-09-19 17:30:44.625356</td>\n",
       "      <td>[-0.18336365,0.04164475,-0.20463689,-0.2488077...</td>\n",
       "      <td>5.747982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5381030408</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>Lead Data Scientist/ Python/ Looker / GCP/ Ver...</td>\n",
       "      <td>Nous recherchons pour le compte de notre clien...</td>\n",
       "      <td>Octopus Group</td>\n",
       "      <td>Ivry-sur-Seine, Cr√©teil</td>\n",
       "      <td>48.80780</td>\n",
       "      <td>2.374620</td>\n",
       "      <td>IVRY-SUR-SEINE</td>\n",
       "      <td>94041</td>\n",
       "      <td>94</td>\n",
       "      <td>contract</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>https://www.adzuna.fr/details/5381030408?utm_m...</td>\n",
       "      <td>Emplois Informatique</td>\n",
       "      <td>2025-09-19 17:30:44.625356</td>\n",
       "      <td>[-0.18336365,0.04164475,-0.20463689,-0.2488077...</td>\n",
       "      <td>5.747982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5380688338</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Data Analyst Senior H/F</td>\n",
       "      <td>Nous recherchons un Data Analyst Senior pour a...</td>\n",
       "      <td>Ekkiden</td>\n",
       "      <td>La-Madeleine, Lille</td>\n",
       "      <td>50.63718</td>\n",
       "      <td>3.063020</td>\n",
       "      <td>LILLE</td>\n",
       "      <td>59350</td>\n",
       "      <td>59</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>https://www.adzuna.fr/details/5380688338?utm_m...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-09-19 17:28:45.671088</td>\n",
       "      <td>[-0.33283094,0.26524156,-0.10381974,-0.2060563...</td>\n",
       "      <td>5.664216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5387798041</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>Alternant Data Analyst H/F</td>\n",
       "      <td>Dans le cadre du d√©veloppement de nos activit√©...</td>\n",
       "      <td>Exco</td>\n",
       "      <td>Paris, Ile-de-France</td>\n",
       "      <td>48.86384</td>\n",
       "      <td>2.344631</td>\n",
       "      <td>PARIS 1ER ARRONDISSEMENT</td>\n",
       "      <td>75101</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-07</td>\n",
       "      <td>https://www.adzuna.fr/details/5387798041?utm_m...</td>\n",
       "      <td>Emplois Autres/G√©n√©ral</td>\n",
       "      <td>2025-09-19 17:28:45.671088</td>\n",
       "      <td>[-0.2326749,0.03829508,-0.12620185,-0.16146821...</td>\n",
       "      <td>5.605638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          source       recherche  \\\n",
       "0     8653579  France Travail    data analyst   \n",
       "1  5378713497          Adzuna  data scientist   \n",
       "2  5381030408          Adzuna  data scientist   \n",
       "3  5380688338          Adzuna    data analyst   \n",
       "4  5387798041          Adzuna    data analyst   \n",
       "\n",
       "                                               titre  \\\n",
       "0             Data Analyst Smart Pricing (F/H) (H/F)   \n",
       "1  Data Scientist/ Python/ Looker / GCP/ VerteX A...   \n",
       "2  Lead Data Scientist/ Python/ Looker / GCP/ Ver...   \n",
       "3                            Data Analyst Senior H/F   \n",
       "4                         Alternant Data Analyst H/F   \n",
       "\n",
       "                                         description     entreprise  \\\n",
       "0  Data Analyst Smart Pricing (F/H) Enregistrer p...           None   \n",
       "1  Nous recherchons pour le compte de notre clien...  Octopus Group   \n",
       "2  Nous recherchons pour le compte de notre clien...  Octopus Group   \n",
       "3  Nous recherchons un Data Analyst Senior pour a...        Ekkiden   \n",
       "4  Dans le cadre du d√©veloppement de nos activit√©...           Exco   \n",
       "\n",
       "                      lieu  latitude  longitude                   commune  \\\n",
       "0       93 - AUBERVILLIERS  48.91456   2.381792             AUBERVILLIERS   \n",
       "1  Ivry-sur-Seine, Cr√©teil  48.80780   2.374620            IVRY-SUR-SEINE   \n",
       "2  Ivry-sur-Seine, Cr√©teil  48.80780   2.374620            IVRY-SUR-SEINE   \n",
       "3      La-Madeleine, Lille  50.63718   3.063020                     LILLE   \n",
       "4     Paris, Ile-de-France  48.86384   2.344631  PARIS 1ER ARRONDISSEMENT   \n",
       "\n",
       "  code_postal departement          type_contrat_libelle date_publication  \\\n",
       "0       93001          93  Contrat √† dur√©e ind√©termin√©e       2025-06-24   \n",
       "1       94041          94                      contract       2025-09-02   \n",
       "2       94041          94                      contract       2025-09-03   \n",
       "3       59350          59                          None       2025-09-03   \n",
       "4       75101          75                          None       2025-09-07   \n",
       "\n",
       "                                                 url       secteur_activites  \\\n",
       "0  https://candidat.francetravail.fr/offres/reche...                    None   \n",
       "1  https://www.adzuna.fr/details/5378713497?utm_m...    Emplois Informatique   \n",
       "2  https://www.adzuna.fr/details/5381030408?utm_m...    Emplois Informatique   \n",
       "3  https://www.adzuna.fr/details/5380688338?utm_m...                 Unknown   \n",
       "4  https://www.adzuna.fr/details/5387798041?utm_m...  Emplois Autres/G√©n√©ral   \n",
       "\n",
       "                last_updated  \\\n",
       "0 2025-09-19 10:46:31.945979   \n",
       "1 2025-09-19 17:30:44.625356   \n",
       "2 2025-09-19 17:30:44.625356   \n",
       "3 2025-09-19 17:28:45.671088   \n",
       "4 2025-09-19 17:28:45.671088   \n",
       "\n",
       "                                           embedding     simil  \n",
       "0  [-0.45374092,0.250378,-0.28020337,-0.29035896,...  6.131842  \n",
       "1  [-0.18336365,0.04164475,-0.20463689,-0.2488077...  5.747982  \n",
       "2  [-0.18336365,0.04164475,-0.20463689,-0.2488077...  5.747982  \n",
       "3  [-0.33283094,0.26524156,-0.10381974,-0.2060563...  5.664216  \n",
       "4  [-0.2326749,0.03829508,-0.12620185,-0.16146821...  5.605638  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIN DU SCRIPT !!!...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# MAIN\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    JOB_QUERY = [\"data analyst\",\"data scientist\"]\n",
    "    for query in JOB_QUERY:\n",
    "        run_pipeline(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
